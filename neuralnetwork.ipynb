{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60da8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"features.csv\", sep=\";\")\n",
    "df = df.drop('semanticobjscore', axis=1) \n",
    "df = df.drop('semanticsubjscore', axis=1) \n",
    "df = df.drop('URL', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['objective' 'subjective']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.drop(['Label', 'TextID'], axis=1)  \n",
    "y = df['Label']\n",
    "\n",
    "# Convertir les labels en nombres\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(\"Classes:\", le.classes_)  # Pour voir la correspondance\n",
    "\n",
    "# Refaire la séparation train/test/val avec les labels encodés\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.2,          \n",
    "    random_state=3,         \n",
    "    stratify=y_encoded      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07fe20",
   "metadata": {},
   "source": [
    "La fonction MLPClassifier prend par défaut ReLu comme fonction d'activation et la fonction sigmoïde pour la couche de sortie (car on est dans un cas binaire). L'algorithme par défaut est l'algorithme Adam (avec taux d'apprentissage 0,001 et taux de régularisation 0,0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc0fdf",
   "metadata": {},
   "source": [
    "LÀ ON VA UTILISER RANDOMSEARCH POUR CHOISIR LES HYPERPARAMÈTRES AU MIEUX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import loguniform, uniform, randint # Pour définir des distributions\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model_base = MLPClassifier(max_iter=2000, random_state=3)\n",
    "\n",
    "\n",
    "\n",
    "# Nous définissons l'espace de recherche (le \"param_dist\")\n",
    "param_dist = {\n",
    "    # 1. Architecture (hidden_layer_sizes) : C'est une liste de tuples à choisir\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50), (128, 64)], \n",
    "    \n",
    "    # 2. Régularisation (alpha) : Loguniform est idéal pour les paramètres de régularisation\n",
    "    'alpha': loguniform(1e-5, 1e-2), # Exemple: choisir une valeur entre 0.00001 et 0.01\n",
    "    \n",
    "    # 3. Optimisation (learning_rate_init) : Loguniform est aussi bon pour le taux d'apprentissage\n",
    "    'learning_rate_init': loguniform(1e-4, 1e-2), # Exemple: choisir une valeur entre 0.0001 et 0.01\n",
    "    \n",
    "    # 4. Fonction d'activation : Une liste de choix discrets\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    \n",
    "    # 5. Type de solveur : Une liste de choix discrets\n",
    "    'solver': ['adam', 'sgd'] \n",
    "}\n",
    "\n",
    "\n",
    "# Instanciation de RandomizedSearchCV\n",
    "# n_iter=50 : Le nombre total d'itérations aléatoires que nous voulons tester (compromis temps/précision)\n",
    "# scoring='f1' : La métrique sur laquelle nous arbitrons (maximiser le F1-score)\n",
    "# cv=5 : Utilise la validation croisée K-Fold avec 5 plis (plus fiable qu'un simple split Train/Val)\n",
    "# verbose=2 : Affiche le progrès détaillé\n",
    "# n_jobs=-1 : Utilise tous les cœurs du processeur pour accélérer le calcul\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50, \n",
    "    scoring='precision', \n",
    "    cv=5, \n",
    "    random_state=3, \n",
    "    verbose=2,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "# X_train et y_train sont les données utilisées pour la recherche d'hyperparamètres.\n",
    "# L'objet random_search effectue l'entraînement et la validation croisée en interne.\n",
    "print(\"Début de la recherche aléatoire...\")\n",
    "random_search.fit(X_train_scaled, y_train) \n",
    "print(\"Recherche aléatoire terminée.\")\n",
    "\n",
    "\n",
    "# Récupération du meilleur jeu d'hyperparamètres (celui qui a maximisé le Score de précision CV)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Récupération du modèle qui a obtenu le meilleur score de validation croisée\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"\\n---------------------------------------------\")\n",
    "print(\"MEILLEURS HYPERPARAMÈTRES TROUVÉS (JUSTIFICATION) :\")\n",
    "print(best_params)\n",
    "print(f\"Meilleur score de validation croisée (Score de précision) : {random_search.best_score_:.4f}\")\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Évaluation finale sur l'ensemble de TEST\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "test_precision = precision_score(y_test, y_pred_test)\n",
    "print(f\"Performance finale sur la base de TEST : Score de précision = {test_precision:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
